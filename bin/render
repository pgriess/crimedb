#!/bin/env python3.3
#
# Copyright 2014 Peter Griess
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Process raw CrimeDB data files and render optimized data for www.

import argparse
from collections import defaultdict
import datetime
import json
import logging
import math
import os
import os.path
import pystache
import pytz
import shapely.geometry
import sys

# Add src/ directory to PYTHONPATH so that this can be run without the operator
# having to configure that manually
sys.path += [os.path.join(os.path.dirname(sys.argv[0]), '..', 'src')]

import crimedb.cli
import crimedb.core

# Grid size in lat/lon degrees
GRID_SIZE = 0.002

UTC_TZ = pytz.timezone('UTC')

def crimedb_filenames_for_date_range(begin, end):
    filenames = set()

    current_date = begin
    while current_date < end:
        filenames.add(current_date.strftime('%Y-%m.json'))
        current_date += datetime.timedelta(days=1)

    return filenames


def cmd_grid(args):
    with open(os.path.join(args.data_dir, 'index.json'), 'rt') as mf:
        meta_obj = json.load(mf)

    region = shapely.geometry.shape(meta_obj['geo'])

    # Compute our bounding box, snapped to GRID_SIZE
    lon_min, lat_min, lon_max, lat_max = region.bounds
    lon_min -= lon_min % GRID_SIZE
    lat_min -= lat_min % GRID_SIZE
    lon_max += GRID_SIZE - (lon_max % GRID_SIZE)
    lat_max += GRID_SIZE - (lat_max % GRID_SIZE)
    logging.info('Bounding box is ({}, {}), ({}, {})'.format(
        lon_min, lat_min, lon_max, lat_max))

    # Compute grid dimensions
    grid_width = int(round((lon_max - lon_min) / GRID_SIZE))
    grid_height = int(round((lat_max - lat_min) / GRID_SIZE))
    logging.info('Rendering into {} x {} grid'.format(grid_width, grid_height))

    # Create an empty grid, populated with initial values of 0 for cells that are
    # in our region and -1 those that are not
    grid = []
    for x in range(0, grid_width):
        col = []
        for y in range(0, grid_height):
            cell = shapely.geometry.box(
                round(lon_min + x * GRID_SIZE, 3),
                round(lat_min + y * GRID_SIZE, 3),
                round(lon_min + (x + 1) * GRID_SIZE, 3),
                round(lat_min + (y + 1) * GRID_SIZE, 3))
            v = 0 if cell.intersects(region) else -1
            col += [v]
        grid.append(col)

    # Read crime data from date range
    crimes = []
    for fn in crimedb_filenames_for_date_range(args.time_from, args.time_to):
        fp = os.path.join(args.data_dir, fn)
        if not os.path.isfile(fp):
            continue

        def crime_filter(c):
            ct = datetime.datetime.strptime(
                    c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
            return ct >= args.time_from and ct <= args.time_to

        with open(fp, 'rt') as cf:
            crimes += [c for c in json.load(cf)['crimes'] if crime_filter(c)]

    # Populate the grid with aggregates
    for c in crimes:
        # Some crimes could not be geocoded; skip them
        if 'geo' not in c:
            continue

        lon, lat = c['geo']['coordinates']
        assert lon > lon_min and lon < lon_max
        assert lat > lat_min and lat < lat_max

        x = math.floor((lon - lon_min) / GRID_SIZE)
        y = math.floor((lat - lat_min) / GRID_SIZE)
        assert x >= 0 and x < grid_width
        assert y >= 0 and y < grid_height

        # TODO: This should never happen based on our region clipping when
        #       importing crimes, and based on our cell model above. Figure out
        #       what the disconnect is, but for now just skip.
        if grid[x][y] < 0:
            logging.error('cell ({}, {}) contains crime; is outside region'.format(x, y))
            continue

        grid[x][y] += 1

    # Render the JSON output file
    jo = {
        'origin': {
            'type': 'Point',
            'coordinates': [lon_min, lat_min]
        },
        'grid_size': GRID_SIZE,
        'grid': grid
    }

    json.dump(jo, sys.stdout)


def cmd_timeseries(args):
    # Read crime data from date range
    crimes = []
    for fn in crimedb_filenames_for_date_range(args.time_from, args.time_to):
        fp = os.path.join(args.data_dir, fn)
        if not os.path.isfile(fp):
            continue

        def crime_filter(c):
            ct = datetime.datetime.strptime(
                    c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
            return ct >= args.time_from and ct <= args.time_to

        with open(fp, 'rt') as cf:
            all_crimes = json.load(cf)['crimes']
            filtered_crimes = [c for c in all_crimes if crime_filter(c)]
            crimes += filtered_crimes

            logging.info('{} of {} crimes from {} matched time range'.format(
                len(filtered_crimes), len(all_crimes), fp))

    crimes_by_month = defaultdict(lambda: [0] * 12)
    crimes_by_weekday = defaultdict(lambda: [0] * 7)
    for c in crimes:
        ct = datetime.datetime.strptime(
                c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
        crimes_by_month[ct.strftime('%Y')][ct.month - 1] += 1
        crimes_by_weekday[ct.strftime('%Y')][ct.weekday() - 1] += 1

    # Render the JSON output file
    jo = {
        'by_month': {
            'chart': {
                'type': 'line',
            },
            'title': {
                'text': 'Crimes by Month',
            },
            'xAxis': {
                'categories': [
                    'Jan',
                    'Feb',
                    'Mar',
                    'Apr',
                    'May',
                    'Jun',
                    'Jul',
                    'Aug',
                    'Sep',
                    'Oct',
                    'Nov',
                    'Dec',
                ],
            },
            'yAxis': {
                'title': {
                    'text': 'Number of crimes',
                },
            },
            'series': [
                {'name': x, 'data': crimes_by_month[x]} for x in crimes_by_weekday],
        },
        'by_weekday': {
            'chart': {
                'type': 'line',
            },
            'title': {
                'text': 'Crimes by Weekday',
            },
            'xAxis': {
                'categories': [
                    'Mon',
                    'Tue',
                    'Wed',
                    'Thu',
                    'Fri',
                    'Sat',
                    'Sun',
                ],
            },
            'yAxis': {
                'title': {
                    'text': 'Number of crimes',
                },
            },
            'series': [
                {'name': x, 'data': crimes_by_weekday[x]} for x in crimes_by_weekday],
        },
    }

    json.dump(jo, sys.stdout)


def cmd_html(args):
    # Create our pystache context object
    region_path = os.path.join(args.data_dir, 'index.json')
    with open(region_path, 'rt', encoding='utf-8') as rf:
        ro = json.load(rf, encoding='utf-8')

    rs = shapely.geometry.shape(ro['geo'])

    context = {
        'name': ro['name'],
        'timeslice': 'from {} to {}'.format(
                args.time_from.strftime('%B %d, %Y'),
                args.time_to.strftime('%B %d, %Y')),
        'source': ro['source'],
        'center_lon': rs.centroid.x,
        'center_lat': rs.centroid.y,
    }

    # Walk the template directory rendering any template files to the
    # destination
    for root, dirs, files in os.walk(args.template_dir):
        for fn in files:
            if fn.startswith('.'):
                continue

            sp = os.path.join(root, fn)
            logging.debug('loading template {}'.format(sp))
            with open(sp, 'rt', encoding='utf-8') as sf:
                source_data = sf.read()

            rp = os.path.relpath(sp, args.template_dir)
            dp = os.path.join(args.output_dir, rp)
            with open(dp, 'wt', encoding='utf-8') as df:
                df.write(pystache.render(source_data, context))


ap = argparse.ArgumentParser(
        description='''
Download crime data from original sources and transform it into CrimeDB JSON
files.
''',
        parents=[
            crimedb.cli.logging_argument_parser,
            crimedb.cli.config_argument_parser])
ap.add_argument('--time-from', type=int, default=None, metavar='<secs>',
                help='''
Render crimes occurring after this time in epoch seconds UTC (default: one
month ago)
''')
ap.add_argument('--time-to', type=int, default=None, metavar='<secs>',
                help='''
Render crimes occurring before this time in epoch seconds UTC (default: now)
''')

sp = ap.add_subparsers()

grid_parser = sp.add_parser('grid', help='render JSON data grid file')
grid_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('read CrimeDB JSON raw data files from this directory'))
grid_parser.set_defaults(func=cmd_grid)

ts_parser = sp.add_parser('timeseries', help='render JSON timeseries file')
ts_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('read CrimeDB JSON raw data files from this directory'))
ts_parser.set_defaults(func=cmd_timeseries)

html_parser = sp.add_parser('templates', help='render templates')
html_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('read CrimeDB JSON raw data files from this directory'))
html_parser.add_argument(
    'template_dir', metavar='<template-dir>',
    help=('read templates from this directory'))
html_parser.add_argument(
    'output_dir', metavar='<out-dir>',
    help=('write expanded templates to this directory'))
html_parser.set_defaults(func=cmd_html)

args = ap.parse_args()
crimedb.cli.process_logging_args(args)
crimedb.cli.process_config_args(args, defaults={})

if args.time_to is None:
    args.time_to = UTC_TZ.localize(datetime.datetime.utcnow())
else:
    args.time_to = UTC_TZ.localize(
            datetime.datetime.utcfromtimestamp(args.time_to))

if args.time_from is None:
    args.time_from = UTC_TZ.localize(
            datetime.datetime.utcnow() - datetime.timedelta(30))
else:
    args.time_from = UTC_TZ.localize(
            datetime.datetime.utcfromtimestamp(args.time_from))

args.func(args)
