#!/bin/env python3.3
#
# Copyright 2014 Peter Griess
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Process raw CrimeDB data files and render optimized data for www.

import argparse
from collections import defaultdict
import datetime
import json
import logging
import math
import os
import os.path
import pystache
import pytz
import shapely.geometry
import sys

# Add src/ directory to PYTHONPATH so that this can be run without the operator
# having to configure that manually
sys.path += [os.path.join(os.path.dirname(sys.argv[0]), '..', 'src')]

import crimedb.cli
import crimedb.core
import crimedb.www

# Grid size in lat/lon degrees
GRID_SIZE = 0.002

UTC_TZ = pytz.timezone('UTC')

MAX_ZOOM_LEVEL = 14
GRID_CELL_ZOOM_DEPTH = 3

def crimedb_filenames_for_date_range(begin, end):
    filenames = set()

    current_date = begin
    while current_date < end:
        filenames.add(current_date.strftime('%Y-%m.json'))
        current_date += datetime.timedelta(days=1)

    return filenames


def grid_for_region(args, region_dir, zoom):
    # Read crime data from date range
    crimes = []
    for fn in crimedb_filenames_for_date_range(args.time_from, args.time_to):
        fp = os.path.join(region_dir, fn)
        if not os.path.isfile(fp):
            continue

        def crime_filter(c):
            # Some crimes do not have a location (e.g. because they could not
            # be geocoded)
            if 'geo' not in c:
                return False

            # Crimes must be within the expected time range
            ct = datetime.datetime.strptime(
                    c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
            if ct < args.time_from or ct > args.time_to:
                return False

            return True

        with open(fp, 'rt') as cf:
            crimes += [c for c in json.load(cf)['crimes'] if crime_filter(c)]

    grid = crimedb.www.grid_from_crimes(crimes, zoom)

    # We need to inject 0s for cells that are within our region but have no
    # crimes. Without this, the sparse cells will not be set and will thus be
    # interpreted as out-of-region rather than real 0s.
    with open(os.path.join(region_dir, 'index.json'), 'rt', encoding='utf-8') as mf:
        region_shape = shapely.geometry.shape(json.load(mf)['geo'])

    # Compute the range of (x, y) tile coordinates at our zoom level that are
    # within the region.
    #
    # NOTE: Since the Slippy map coordinate system has its origin at (-180W, +85N)
    #       the maximum latitude is our minimum Y value while the maximum longitude
    #       is our maximum X value.
    lon_min, lat_min, lon_max, lat_max = region_shape.bounds
    minx, maxy = crimedb.www.slippy_tile_coordinates_from_point(
            lon_min, lat_min, zoom)
    maxx, miny = crimedb.www.slippy_tile_coordinates_from_point(
            lon_max, lat_max, zoom)

    for x in range(minx, maxx + 1):
        for y in range(miny, maxy + 1):
            cell_shape = crimedb.www.bbox_from_slippy_tile_coordinates(x, y, zoom)
            if region_shape.intersects(cell_shape) and \
                    y not in grid[x]:
                grid[x][y] += 0

    return grid


def cmd_grid(args):
    initial_zoom_level = MAX_ZOOM_LEVEL + GRID_CELL_ZOOM_DEPTH
    grid = crimedb.www.grid_from_crimes([], initial_zoom_level)
    for rn in os.listdir(args.data_dir):
        rp = os.path.join(args.data_dir, rn)
        if not os.path.isdir(rp):
            continue

        logging.info('Reading raw data for {}'.format(rn))
        grid = crimedb.www.grid_add(
                grid,
                grid_for_region(args, rp, initial_zoom_level))

    zgrid = crimedb.www.zgrid_from_grid(grid, initial_zoom_level, 0)
    rzgrid = crimedb.www.rzgrid_from_zgrid(zgrid, GRID_CELL_ZOOM_DEPTH)

    for z, xgrids in rzgrid.items():
        for x, ygrids in xgrids.items():
            for y, grid in ygrids.items():
                dp = os.path.join(args.output_dir, str(z), str(x))
                if not os.path.isdir(dp):
                    os.makedirs(dp)
                gjo = crimedb.www.rzgrid_to_geojson(rzgrid, x, y, z, GRID_CELL_ZOOM_DEPTH)
                with open(os.path.join(dp, '{}.json'.format(y)), 'wt', encoding='utf-8') as of:
                    json.dump(gjo, of)


def cmd_timeseries(args):
    # Read crime data from date range
    crimes = []
    for fn in crimedb_filenames_for_date_range(args.time_from, args.time_to):
        fp = os.path.join(args.data_dir, fn)
        if not os.path.isfile(fp):
            continue

        def crime_filter(c):
            ct = datetime.datetime.strptime(
                    c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
            return ct >= args.time_from and ct <= args.time_to

        with open(fp, 'rt') as cf:
            all_crimes = json.load(cf)['crimes']
            filtered_crimes = [c for c in all_crimes if crime_filter(c)]
            crimes += filtered_crimes

            logging.info('{} of {} crimes from {} matched time range'.format(
                len(filtered_crimes), len(all_crimes), fp))

    crimes_by_month = defaultdict(lambda: [0] * 12)
    crimes_by_weekday = defaultdict(lambda: [0] * 7)
    for c in crimes:
        ct = datetime.datetime.strptime(
                c['time'], crimedb.core.RFC3999_STRFTIME_FORMAT)
        crimes_by_month[ct.strftime('%Y')][ct.month - 1] += 1
        crimes_by_weekday[ct.strftime('%Y')][ct.weekday() - 1] += 1

    # Render the JSON output file
    jo = {
        'by_month': {
            'chart': {
                'type': 'line',
            },
            'title': {
                'text': 'Crimes by Month',
            },
            'xAxis': {
                'categories': [
                    'Jan',
                    'Feb',
                    'Mar',
                    'Apr',
                    'May',
                    'Jun',
                    'Jul',
                    'Aug',
                    'Sep',
                    'Oct',
                    'Nov',
                    'Dec',
                ],
            },
            'yAxis': {
                'title': {
                    'text': 'Number of crimes',
                },
            },
            'series': [
                {'name': x, 'data': crimes_by_month[x]} for x in crimes_by_weekday],
        },
        'by_weekday': {
            'chart': {
                'type': 'line',
            },
            'title': {
                'text': 'Crimes by Weekday',
            },
            'xAxis': {
                'categories': [
                    'Mon',
                    'Tue',
                    'Wed',
                    'Thu',
                    'Fri',
                    'Sat',
                    'Sun',
                ],
            },
            'yAxis': {
                'title': {
                    'text': 'Number of crimes',
                },
            },
            'series': [
                {'name': x, 'data': crimes_by_weekday[x]} for x in crimes_by_weekday],
        },
    }

    json.dump(jo, sys.stdout)


def cmd_templates(args):
    # Create our pystache context object
    region_path = os.path.join(args.data_dir, 'index.json')
    with open(region_path, 'rt', encoding='utf-8') as rf:
        ro = json.load(rf, encoding='utf-8')

    rs = shapely.geometry.shape(ro['geo'])

    context = {
        'region': os.path.basename(args.data_dir),
        'name': ro['name'],
        'timeslice': 'from {} to {}'.format(
                args.time_from.strftime('%B %d, %Y'),
                args.time_to.strftime('%B %d, %Y')),
        'source': ro['source'],
        'center_lon': rs.centroid.x,
        'center_lat': rs.centroid.y,
    }

    # Walk the template directory rendering any template files to the
    # destination
    for root, dirs, files in os.walk(args.template_dir):
        for fn in files:
            if fn.startswith('.'):
                continue

            sp = os.path.join(root, fn)
            logging.debug('loading template {}'.format(sp))
            with open(sp, 'rt', encoding='utf-8') as sf:
                source_data = sf.read()

            rp = os.path.relpath(sp, args.template_dir)
            dp = os.path.join(args.output_dir, rp)
            if not os.path.isdir(os.path.dirname(dp)):
                os.makedirs(os.path.dirname(dp))

            with open(dp, 'wt', encoding='utf-8') as df:
                df.write(pystache.render(source_data, context))


ap = argparse.ArgumentParser(
        description='''
Download crime data from original sources and transform it into CrimeDB JSON
files.
''',
        parents=[
            crimedb.cli.logging_argument_parser,
            crimedb.cli.config_argument_parser])
ap.add_argument('--time-from', type=int, default=None, metavar='<secs>',
                help='''
Render crimes occurring after this time in epoch seconds UTC (default: one
month ago)
''')
ap.add_argument('--time-to', type=int, default=None, metavar='<secs>',
                help='''
Render crimes occurring before this time in epoch seconds UTC (default: now)
''')

sp = ap.add_subparsers()

grid_parser = sp.add_parser('grid', help='render JSON data grid file')
grid_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('''
read CrimeDB JSON raw data files from this directory; should contain a
subdirectory for each region
'''))
grid_parser.add_argument(
    'output_dir', metavar='<output-dir>',
    help='''
Write grid tiles to the given directory.
''')
grid_parser.set_defaults(func=cmd_grid)

ts_parser = sp.add_parser('timeseries', help='render JSON timeseries file')
ts_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('read CrimeDB JSON raw data files from this directory'))
ts_parser.set_defaults(func=cmd_timeseries)

html_parser = sp.add_parser('templates', help='render templates')
html_parser.add_argument(
    'data_dir', metavar='<data-dir>',
    help=('read CrimeDB JSON raw data files from this directory'))
html_parser.add_argument(
    'template_dir', metavar='<template-dir>',
    help=('read templates from this directory'))
html_parser.add_argument(
    'output_dir', metavar='<out-dir>',
    help=('write expanded templates to this directory'))
html_parser.set_defaults(func=cmd_templates)

args = ap.parse_args()
crimedb.cli.process_logging_args(args)
crimedb.cli.process_config_args(args, defaults={})

if args.time_to is None:
    args.time_to = UTC_TZ.localize(datetime.datetime.utcnow())
else:
    args.time_to = UTC_TZ.localize(
            datetime.datetime.utcfromtimestamp(args.time_to))

if args.time_from is None:
    args.time_from = UTC_TZ.localize(
            datetime.datetime.utcnow() - datetime.timedelta(30))
else:
    args.time_from = UTC_TZ.localize(
            datetime.datetime.utcfromtimestamp(args.time_from))

args.func(args)
